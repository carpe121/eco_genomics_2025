---
title: "Tonsa DESeq2"
author: "Madeline Carpenter"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir="~/projects/eco_genomics_2025/transcriptomics/")
```

```{r, quiet=TRUE}
## Import libraries

library(DESeq2)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggpubr)
library(vsn)  
library("pheatmap")
library("vsn")
```

```{r}
####################################################

### Import our data

####################################################

 
# Import the counts matrix
countsTable <- read.table("/gpfs1/home/m/c/mcarpen3/projects/eco_genomics_2025/transcriptomics/mydata/counts_matrix.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)

countsTableRound <- round(countsTable) # bc DESeq2 doesn't like decimals (and Salmon outputs data with decimals)
head(countsTableRound)

#import the sample description table
conds <- read.delim("/gpfs1/cl/ecogen/pbio6800/Transcriptomics/transcripts_quant/metadata.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1)
head(conds)
```

```{r}
####################################################

### Explore data distributions

####################################################

# Let's see how many reads we have from each sample
colSums(countsTableRound)
mean(colSums(countsTableRound))
```
Note that we are below the general rule of thumb recommendation of 20 million reads per sample. We're at about 12M reads/sample.

```{r}
barplot(colSums(countsTableRound), names.arg=colnames(countsTableRound),cex.names=0.5, las=3,ylim=c(0,21000000)) #change dims
abline(h=mean(colSums(countsTableRound)), col="blue", lwd=2)

mean(rowSums(countsTableRound)) # 
```
Despite lots of zeroes across the 119,000 transcripts, we still have an average of 2500 reads mapping per transcript.

```{r}
median(rowSums(countsTableRound)) #

apply(countsTableRound,2,mean) # 2 in the apply function does the action across columns
apply(countsTableRound,1,mean) # 1 in the apply function does the action across rows
hist(apply(countsTableRound,1,mean), ylim=c(0,100000),breaks=10000)
```

```{r}
####################################################

### Start working with DESeq2!

####################################################

# Correct column names to match conds
colnames(countsTableRound) <- substr(colnames(countsTableRound), start=1, stop=4)
```

```{r}
#### Create a DESeq object and define the experimental design here with the tilda
dds <- DESeqDataSetFromMatrix(countData = countsTableRound, colData=conds, design= ~ generation + line + line:generation)

dim(dds)
```

```{r}
# Filter out genes with too few reads - remove all genes with counts < 15 in more than 75% of 24 samples, so 18)
## suggested by WGCNA on RNAseq FAQ

dds <- dds[rowSums(counts(dds) >= 15) >= 18,]
nrow(dds)
# How many transcripts have at least 15 reads (a.k.a counts) in 75% of the samples

# Run the DESeq model to test for differential gene expression
dds <- DESeq(dds)

# List the results you've generated
resultsNames(dds)
# Copy the results names
```

```{r}
####################################################

### Check the quality of the data by sample clustering and visualization

####################################################

# The goal of transformation "is to remove the dependence of the variance on the mean, particularly the high variance of the logarithm of count data when the mean is low."

library("pheatmap")
library("vsn")

# this gives log2(n + 1)
ntd <- normTransform(dds)
meanSdPlot(assay(ntd))

# Variance stabilizing transformation
vsd <- vst(dds, blind=FALSE)
meanSdPlot(assay(vsd))


sampleDists <- dist(t(assay(vsd)))

library("RColorBrewer")
sampleDistMatrix <- as.matrix(sampleDists)
rownames(sampleDistMatrix) <- paste(vsd$line, vsd$generation, sep="-")
colnames(sampleDistMatrix) <- NULL
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)
pheatmap(sampleDistMatrix,
         clustering_distance_rows=sampleDists,
         clustering_distance_cols=sampleDists,
         col=colors)

# Note any outliers

# lack of any irregularities in red line indicates it has been variance-stabilized
```

```{r}
sampleTree <- hclust(dist(sampleDists), method="average")
# plot
plot(sampleTree, main="Sample clustering to detect outliers", sub="", xlab="",cex.lab=1.5, cex.axis=1.5, cex.main=2)
```

```{r}
###############################################################

# PCA to visualize global gene expression patterns

# first transform the data for plotting using variance stabilization
vsd <- vst(dds, blind=FALSE)

pcaData <- plotPCA(vsd, intgroup=c("line","generation"), returnData=TRUE)
percentVar <- round(100 * attr(pcaData,"percentVar"))

ggplot(pcaData, aes(PC1, PC2, color=line, shape=generation)) +
  geom_point(size=3) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  coord_fixed()
```

```{r}
ggplot(pcaData, aes(PC1, PC2)) +
  geom_point(size=5, stroke = 1, aes(fill=line, shape=generation, alpha = generation)) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  scale_shape_manual(values=c(21,22,23,24), labels = c("G1", "G2","G3", "G4"))+
  #scale_shape_manual(values=c(21,22,23,24) -> circle, square, diamond, triangle
  scale_fill_manual(values=c('#6699CC',"#CC3333"), labels = c("Control", "Treatment"))+
  scale_alpha_manual(values = c(1.0, 0.8, 0.7, 0.3), guide = "none") +
  theme_bw() +
  theme(legend.position = "none") +
  theme(panel.border = element_rect(color = "black", fill = NA, size = 3))+
  theme(text = element_text(size = 20)) +
  theme(legend.title = element_blank())
```
## Test for differential gene expression using the group model
```{r}
dds$line <- relevel(dds$line, ref = "control")
dds$generation <- relevel(dds$generation, ref = "G1")


dds$group <- factor(paste0(dds$line, dds$generation))
design(dds) <- ~ group
dds <- DESeq(dds)
resultsNames(dds)

resG1_CvT <- results(dds, contrast=c("group","controlG1","treatmentG1"), alpha = 0.05)
```

```{r}
summary(resG1_CvT)
```

## Reorder by significance
```{r}
resG1_CvT <- resG1_CvT[order(resG1_CvT$padj),]
head(resG1_CvT)
```

```{r}
# Counts of specific top interaction gene! (important validation that the normalization, model is working)
d <-plotCounts(dds, gene="TRINITY_DN136145_c6_g8_i4", intgroup = (c("line","generation")), returnData=TRUE)
d

p <-ggplot(d, aes(x=line, y=count, color=line, shape=generation)) +
  theme_minimal() + theme(text = element_text(size=20), panel.grid.major=element_line(colour="grey"))
p <- p + geom_point(position=position_jitter(w=0.2,h=0), size=3)
p <- p + stat_summary(fun = mean, geom = "point", size=5, alpha=0.7)
p

plotMA(resG1_CvT, ylim=c(-5,5))

topgenes <- head(rownames(resG1_CvT),100)
mat <- assay(vsd)[topgenes,]
mat <- mat - rowMeans(mat)
df <- as.data.frame(colData(dds)[,c("generation","line")])
pheatmap(mat, annotation_col=df)
pheatmap(mat, annotation_col=df, cluster_cols = F)
```

```{r}
#Gen1
resG1_CvT <- results(dds, contrast=c("group","controlG1","treatmentG1"), alpha = 0.05)
resG1_CvT <- resG1_CvT[order(resG1_CvT$padj),] #sort
head(resG1_CvT)
summary(resG1_CvT)

resG1_CvT <- resG1_CvT[!is.na(resG1_CvT$padj),]
degs_G1_CvTM <- row.names(resG1_CvT[resG1_CvT$padj < 0.05,])

#Gen2
resG2_CvT <- results(dds, contrast=c("group","controlG2","treatmentG2"), alpha = 0.05)
resG2_CvT <- resG2_CvT[order(resG2_CvT$padj),] #sort
head(resG2_CvT)
summary(resG2_CvT)

resG2_CvT <- resG2_CvT[!is.na(resG2_CvT$padj),]
degs_G2_CvTM <- row.names(resG2_CvT[resG2_CvT$padj < 0.05,])

#Gen3
resG3_CvT <- results(dds, contrast=c("group","controlG3","treatmentG3"), alpha = 0.05)
resG3_CvT <- resG3_CvT[order(resG3_CvT$padj),] #sort
head(resG3_CvT)
summary(resG3_CvT)

resG3_CvT <- resG3_CvT[!is.na(resG3_CvT$padj),]
degs_G3_CvTM <- row.names(resG3_CvT[resG3_CvT$padj < 0.05,])

#Gen4
resG4_CvT <- results(dds, contrast=c("group","controlG4","treatmentG4"), alpha = 0.05)
resG4_CvT <- resG4_CvT[order(resG4_CvT$padj),] #sort
head(resG4_CvT)
summary(resG4_CvT)

resG4_CvT <- resG4_CvT[!is.na(resG4_CvT$padj),]
degs_G4_CvTM <- row.names(resG4_CvT[resG4_CvT$padj < 0.05,])

library(eulerr)

# Total
length(degs_G1_CvTM)  # 
length(degs_G2_CvTM)  #  
length(degs_G3_CvTM)  # 
length(degs_G4_CvTM)  # 

# Intersections
length(intersect(degs_G1_CvTM,degs_G2_CvTM))  
length(intersect(degs_G1_CvTM,degs_G3_CvTM)) 
#length(intersect(degs_G1_CvTM,degs_G4_CvTM)) 

length(intersect(degs_G2_CvTM,degs_G3_CvTM))  
#length(intersect(degs_G2_CvTM,degs_G4_CvTM))  

#length(intersect(degs_G3_CvTM,degs_G4_CvTM)) 

# To calc number shared in all three contrasts
int12 <- intersect(degs_G1_CvTM,degs_G2_CvTM)
length(intersect(degs_G3_CvTM,int12)) 

# Number unique

 #  OA
 #  OW 
 #  OWA


# G1&G2
# G1&G3
# G2&G3

# Note that the names are important and have to be specific to line up the diagram
fit1 <- euler(c("G1" = , "G2" = , "G3" = , "G1&G2" = , "G1&G3" = , "G2&G3" = , "G1&G2&G3" = ))


plot(fit1,  lty = 1:3, quantities = TRUE)
# lty changes the lines

plot(fit1, quantities = TRUE, fill = "transparent",
     lty = 1:3,
     labels = list(font = 4))


#cross check
 #  total G1
 #  total G2
 #  total G3
```



